{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import random_normal\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "from DataGen import VQASequence\n",
    "from json_to_df import gen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "img_input_shape = (img_size, img_size, 3)\n",
    "qstn_input_shape = (None, 300)\n",
    "n_most_freq = 200\n",
    "seed = 14\n",
    "test_size = 0.2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 256\n",
    "epochs=100\n",
    "latent_dim = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = gen_df('train')\n",
    "val_df = gen_df('val')\n",
    "\n",
    "df = pd.concat([train_df, val_df])\n",
    "\n",
    "most_freq = df.Question.value_counts().head(n_most_freq).index\n",
    "df = df[df.Question.isin(most_freq)]\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=test_size, stratify=df.Question, random_state=seed)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df.Question, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "\n",
    "train_df.Question.value_counts()[:20].plot.bar(ax=axes[0])\n",
    "val_df.Question.value_counts()[:20].plot.bar(ax=axes[1])\n",
    "test_df.Question.value_counts()[:20].plot.bar(ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = VQASequence(batch_size, train_df, img_size)\n",
    "val_gen = VQASequence(batch_size, val_df, img_size)\n",
    "test_gen = VQASequence(batch_size, test_df, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        # print(z_mean.shape, z_log_var.shape)\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class PoE(Layer):\n",
    "    def call(self, inputs, eps=1e-8):\n",
    "        mean, logvar = inputs\n",
    "        var = tf.exp(logvar) + eps\n",
    "        T = 1. / (var + eps)\n",
    "        pd_mu = tf.reduce_sum(mean * T, 1) / tf.reduce_sum(T, 1)\n",
    "        # print(pd_mu.shape)\n",
    "        pd_var = 1. / tf.reduce_sum(T, 1)\n",
    "        pd_logvar = tf.math.log(pd_var + eps)\n",
    "        return pd_mu, pd_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Input(shape=img_input_shape)\n",
    "\n",
    "img_encoding = Sequential([\n",
    "    Conv2D(8, 3, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(16, 3, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(32, 3, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(64, 3, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(128, 3, strides=2, padding='same', activation='relu'),\n",
    "    Flatten()\n",
    "])(img_in)\n",
    "\n",
    "qstn_in = Input(shape=qstn_input_shape)\n",
    "\n",
    "q_encoding = Sequential([\n",
    "    LSTM(64, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "])(qstn_in)\n",
    "\n",
    "img_logvar = Dense(latent_dim)(img_encoding)\n",
    "img_mean = Dense(latent_dim)(q_encoding)\n",
    "q_logvar = Dense(latent_dim)(img_encoding)\n",
    "q_mean = Dense(latent_dim)(q_encoding)\n",
    "\n",
    "mean = tf.stack([img_mean, q_mean], axis=1)\n",
    "logvar = tf.stack([img_logvar, q_logvar], axis=1)\n",
    "poe_mu, poe_logvar = PoE()([mean, logvar])\n",
    "z = Sampling()([poe_mu, poe_logvar])\n",
    "\n",
    "decoded = Sequential([\n",
    "    Dense(8 * 8 * 128, activation='relu'),\n",
    "    Reshape((8, 8, 128)),\n",
    "    Conv2DTranspose(128, 3, strides=2, padding='same'),\n",
    "    LeakyReLU(),\n",
    "    Conv2DTranspose(64, 3, strides=2, padding='same'),\n",
    "    LeakyReLU(),\n",
    "    Conv2DTranspose(32, 3, strides=2, padding='same'),\n",
    "    LeakyReLU(),\n",
    "    Conv2DTranspose(16, 3, strides=2, padding='same'),\n",
    "    LeakyReLU(),\n",
    "    Conv2DTranspose(1, 3, activation='sigmoid', strides=2, padding='same'),\n",
    "    LeakyReLU(),\n",
    "    Flatten()\n",
    "])(z)\n",
    "\n",
    "output = Sequential([\n",
    "    Dense(latent_dim),\n",
    "    LeakyReLU(),\n",
    "    Dense(latent_dim),\n",
    "    LeakyReLU(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])(decoded)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[img_in, qstn_in], \n",
    "    outputs=output, \n",
    "    name='MVAE_VQA'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'AUC', 'Precision', 'Recall']\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=learning_rate),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "rp = ReduceLROnPlateau(patience=5)\n",
    "es = EarlyStopping(patience=15)\n",
    "\n",
    "callbacks= [rp, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 348s 10s/step - loss: 3.6091 - accuracy: 0.5005 - auc: 0.4967 - recall: 0.4838 - precision: 0.4903 - val_loss: 0.7888 - val_accuracy: 0.5036 - val_auc: 0.5000 - val_recall: 1.0000 - val_precision: 0.5036\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hist.history, open(f'./{model.name}.pickle', 'wb'))\n",
    "\n",
    "def plot(history, metrics):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss', color='red')\n",
    "    plt.legend()\n",
    "    plt.figsave(f'./plots/{model.name}_loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    for metric in metrics:\n",
    "        metric = metric.lower()\n",
    "        plt.plot(history.history[f'{metric}'], label=f'{metric}')\n",
    "        plt.plot(history.history[f'val_{metric}'], label=f'val_{metric}', color='red')\n",
    "        plt.legend()\n",
    "        plt.figsave(f'./plots/{model.name}_{metric}.png')\n",
    "        plt.show()\n",
    "    \n",
    "plot(model.history, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = model.evaluate(x=test_gen, batch_size=batch_size, verbose=0)\n",
    "\n",
    "results_dict = {\n",
    "    'Name' : model.name,\n",
    "    'Loss' : [evaluate[0]],\n",
    "    'Accuracy' : [evaluate[1]],\n",
    "    'AUC' : [evaluate[2]],\n",
    "    'Precision' : [evaluate[3]],\n",
    "    'Recall' : [evaluate[4]]\n",
    "}\n",
    "\n",
    "test_results = pd.DataFrame(data=results_dict)\n",
    "test_results.head(1)\n",
    "test_resuls.to_csv(f'./results/{model.name}_results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
