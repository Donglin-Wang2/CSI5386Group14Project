{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df(v_path, q_path, a_path, to_disk=None):\n",
    "    V_PATH, Q_PATH, A_PATH = v_path, q_path, a_path\n",
    "\n",
    "    id_tuples = []\n",
    "    questions = {}\n",
    "    train_data = []\n",
    "\n",
    "    with open(A_PATH) as f:\n",
    "        data = json.load(f)\n",
    "        for annotation in data['annotations']:\n",
    "            if annotation['answer_type'] == 'yes/no':\n",
    "                id_tuples.append(\n",
    "                    (annotation['image_id'], \n",
    "                    annotation['question_id'],  \n",
    "                    annotation['multiple_choice_answer'])\n",
    "                )\n",
    "    \n",
    "    with open(Q_PATH) as f:\n",
    "        data = json.load(f)\n",
    "        for question in data['questions']:\n",
    "            questions[question['question_id']] = question['question']\n",
    "            \n",
    "    for id_tuple in tqdm(id_tuples):\n",
    "        question = questions[id_tuple[1]]\n",
    "        img = V_PATH + 'COCO_train2014_' + str(id_tuple[0]).zfill(12) + '.jpg'\n",
    "        train_data.append((img, question, id_tuple[-1]))\n",
    "\n",
    "    df = pd.DataFrame(data=train_data, columns=['Image', 'Question', 'Answer'])\n",
    "    df = df[(df.Answer == 'yes') | (df.Answer == 'no')]\n",
    "    if to_disk:\n",
    "        df.to_pickle(to_disk)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def gen_embedding_matrix(df, glove_path, to_disk=None, verbose=True):\n",
    "    EMBEDDING_DIM = 300\n",
    "\n",
    "    vectorizer = TextVectorization(output_sequence_length=100)\n",
    "    vectorizer.adapt(df['Question'].to_numpy())\n",
    "    voc = vectorizer.get_vocabulary()\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "    glove_df = pd.read_csv(glove_path, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    embeddings_index = {key: val.values for key, val in glove_df.T.items()}\n",
    "    embedding_matrix = np.zeros((len(voc), EMBEDDING_DIM))\n",
    "\n",
    "    misses = 0\n",
    "    hits = 0\n",
    "    for word, i in tqdm(word_index.items(), desc=\"Generating matrix\", disable=not verbose):\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "        print(\"Shape of the embedding matrix is: \", end='')\n",
    "        print(embedding_matrix.shape)\n",
    "    if to_disk:\n",
    "        np.save(to_disk, embedding_matrix)\n",
    "\n",
    "    return embedding_matrix, vectorizer\n",
    "\n",
    "def gen_data_iterator(df, vectorizer, img_target_size, batch_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df, \n",
    "        directory='.', \n",
    "        x_col='Image', \n",
    "        y_col='Answer',  \n",
    "        target_size=img_target_size,\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    for i, (image, answer) in enumerate(generator):\n",
    "        questions = df[i*generator.batch_size:(i+1)*(generator.batch_size)]['Question'].to_numpy()\n",
    "        questions = vectorizer(questions)\n",
    "        yield (image, questions), answer\n",
    "\n",
    "train_df = gen_df('./VQA/Images/train2014/',\n",
    "    './VQA/Questions/v2_OpenEnded_mscoco_train2014_questions.json',\n",
    "    './VQA/Annotations/v2_mscoco_train2014_annotations.json')\n",
    "train_df.head()\n",
    "\n",
    "mtx, vectorizer = gen_embedding_matrix(train_df, 'glove.6B.300d.txt', to_disk='./embedding_matrix', verbose=True)\n",
    "print(mtx.shape)\n",
    "\n",
    "data_gen = gen_data_iterator(train_df, vectorizer, (128, 128), 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx, b_idx = np.random.randint(len(train_df)), np.random.randint(64)\n",
    "(i, q), a = next(data_gen)\n",
    "print(q[b_idx], a[b_idx])\n",
    "plt.imshow(i[b_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input_shape = (128, 128, 3)\n",
    "embedding_matrix = np.load('./embedding_matrix.npy')\n",
    "print(embedding_matrix.shape)\n",
    "embedding_layer = Embedding(\n",
    "    embedding_matrix.shape[0],\n",
    "    embedding_matrix.shape[1],\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "# Image \n",
    "vgg = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=img_input_shape,\n",
    "    pooling=True\n",
    ")\n",
    "\n",
    "for layer in vgg.layers: layer.trainable = False\n",
    "\n",
    "img_x = vgg.output\n",
    "img_x = Flatten()(img_x)\n",
    "img_x = BatchNormalization()(img_x)\n",
    "img_x = Dense(1024, activation='relu')(img_x)\n",
    "img_x = BatchNormalization()(img_x)\n",
    "img_output = Dense(1024, activation='relu')(img_x)\n",
    "\n",
    "# Question\n",
    "qstn_input = Input(shape=(None,), dtype=\"int64\")\n",
    "qstn_x = embedding_layer(qstn_input)\n",
    "qstn_x = LSTM(64, activation='tanh')(qstn_x)\n",
    "qstn_x = BatchNormalization()(qstn_x)\n",
    "qstn_x = Dense(1024, activation='relu')(qstn_x)\n",
    "qstn_x = BatchNormalization()(qstn_x)\n",
    "qstn_output = Dense(1024, activation='relu')(qstn_x)\n",
    "# qstn_input = Input(shape=(1,), dtype=tf.string)\n",
    "# qstn_x = vectorizer(qstn_input)\n",
    "# qstn_x = embedding_layer(qstn_x)\n",
    "# qstn_x = LSTM(64, activation='tanh')(qstn_x)\n",
    "# qstn_x = BatchNormalization()(qstn_x)\n",
    "# qstn_x = Dense(1024, activation='relu')(qstn_x)\n",
    "# qstn_x = BatchNormalization()(qstn_x)\n",
    "# qstn_output = Dense(1024, activation='relu')(qstn_x)\n",
    "\n",
    "concat = Concatenate(axis=1)([img_output, qstn_output])\n",
    "x = Dense(1024, activation='relu')(concat)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[vgg.input, qstn_input], \n",
    "    outputs=output, \n",
    "    name='BiModal_VQA'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(lr=1e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "model.fit(x=data_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = 18\n",
    "print(a[haha])\n",
    "print(train_df['Question'][haha])\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python378jvsc74a57bd08608f3369e1b7fe199f3056150d4f7c6c375e24eac93172fa646af6324355164",
   "display_name": "Python 3.7.8 64-bit ('comp5900porj')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}